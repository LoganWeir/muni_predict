{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ftplib import FTP\n",
    "from datetime import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from geopy import distance\n",
    "\n",
    "import get_recent_days as gtdys\n",
    "import muni_etl\n",
    "import labelling as lblng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a Dataframe which has data on each day we will be loading and labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_df = gtdys.x_recent_days(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ftp_filename</th>\n",
       "      <th>iso_string</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>gtfs_directory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sfmtaAVLRawData12052016.csv</td>\n",
       "      <td>2016-12-05</td>\n",
       "      <td>1.480925e+09</td>\n",
       "      <td>sfmta_2017-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sfmtaAVLRawData12042016.csv</td>\n",
       "      <td>2016-12-04</td>\n",
       "      <td>1.480838e+09</td>\n",
       "      <td>sfmta_2017-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sfmtaAVLRawData12032016.csv</td>\n",
       "      <td>2016-12-03</td>\n",
       "      <td>1.480752e+09</td>\n",
       "      <td>sfmta_2017-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfmtaAVLRawData11232016.csv</td>\n",
       "      <td>2016-11-23</td>\n",
       "      <td>1.479888e+09</td>\n",
       "      <td>sfmta_2017-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sfmtaAVLRawData11222016.csv</td>\n",
       "      <td>2016-11-22</td>\n",
       "      <td>1.479802e+09</td>\n",
       "      <td>sfmta_2017-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sfmtaAVLRawData11212016.csv</td>\n",
       "      <td>2016-11-21</td>\n",
       "      <td>1.479715e+09</td>\n",
       "      <td>sfmta_2017-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sfmtaAVLRawData11202016.csv</td>\n",
       "      <td>2016-11-20</td>\n",
       "      <td>1.479629e+09</td>\n",
       "      <td>sfmta_2017-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sfmtaAVLRawData11192016.csv</td>\n",
       "      <td>2016-11-19</td>\n",
       "      <td>1.479542e+09</td>\n",
       "      <td>sfmta_2017-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sfmtaAVLRawData11182016.csv</td>\n",
       "      <td>2016-11-18</td>\n",
       "      <td>1.479456e+09</td>\n",
       "      <td>sfmta_2017-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sfmtaAVLRawData11172016.csv</td>\n",
       "      <td>2016-11-17</td>\n",
       "      <td>1.479370e+09</td>\n",
       "      <td>sfmta_2017-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sfmtaAVLRawData11162016.csv</td>\n",
       "      <td>2016-11-16</td>\n",
       "      <td>1.479283e+09</td>\n",
       "      <td>sfmta_2017-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sfmtaAVLRawData11152016.csv</td>\n",
       "      <td>2016-11-15</td>\n",
       "      <td>1.479197e+09</td>\n",
       "      <td>sfmta_2017-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sfmtaAVLRawData11142016.csv</td>\n",
       "      <td>2016-11-14</td>\n",
       "      <td>1.479110e+09</td>\n",
       "      <td>sfmta_2017-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sfmtaAVLRawData11132016.csv</td>\n",
       "      <td>2016-11-13</td>\n",
       "      <td>1.479024e+09</td>\n",
       "      <td>sfmta_2017-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sfmtaAVLRawData11122016.csv</td>\n",
       "      <td>2016-11-12</td>\n",
       "      <td>1.478938e+09</td>\n",
       "      <td>sfmta_2017-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sfmtaAVLRawData11112016.csv</td>\n",
       "      <td>2016-11-11</td>\n",
       "      <td>1.478851e+09</td>\n",
       "      <td>sfmta_2017-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sfmtaAVLRawData11102016.csv</td>\n",
       "      <td>2016-11-10</td>\n",
       "      <td>1.478765e+09</td>\n",
       "      <td>sfmta_2017-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sfmtaAVLRawData11092016.csv</td>\n",
       "      <td>2016-11-09</td>\n",
       "      <td>1.478678e+09</td>\n",
       "      <td>sfmta_2017-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sfmtaAVLRawData11082016.csv</td>\n",
       "      <td>2016-11-08</td>\n",
       "      <td>1.478592e+09</td>\n",
       "      <td>sfmta_2017-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sfmtaAVLRawData11072016.csv</td>\n",
       "      <td>2016-11-07</td>\n",
       "      <td>1.478506e+09</td>\n",
       "      <td>sfmta_2017-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sfmtaAVLRawData11062016.csv</td>\n",
       "      <td>2016-11-06</td>\n",
       "      <td>1.478416e+09</td>\n",
       "      <td>sfmta_2017-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sfmtaAVLRawData11052016.csv</td>\n",
       "      <td>2016-11-05</td>\n",
       "      <td>1.478329e+09</td>\n",
       "      <td>sfmta_2017-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sfmtaAVLRawData11042016.csv</td>\n",
       "      <td>2016-11-04</td>\n",
       "      <td>1.478243e+09</td>\n",
       "      <td>sfmta_2017-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sfmtaAVLRawData11032016.csv</td>\n",
       "      <td>2016-11-03</td>\n",
       "      <td>1.478156e+09</td>\n",
       "      <td>sfmta_2017-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sfmtaAVLRawData11022016.csv</td>\n",
       "      <td>2016-11-02</td>\n",
       "      <td>1.478070e+09</td>\n",
       "      <td>sfmta_2017-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sfmtaAVLRawData11012016.csv</td>\n",
       "      <td>2016-11-01</td>\n",
       "      <td>1.477984e+09</td>\n",
       "      <td>sfmta_2017-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sfmtaAVLRawData10312016.csv</td>\n",
       "      <td>2016-10-31</td>\n",
       "      <td>1.477897e+09</td>\n",
       "      <td>sfmta_2017-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sfmtaAVLRawData10302016.csv</td>\n",
       "      <td>2016-10-30</td>\n",
       "      <td>1.477811e+09</td>\n",
       "      <td>sfmta_2017-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sfmtaAVLRawData10292016.csv</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>1.477724e+09</td>\n",
       "      <td>sfmta_2017-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sfmtaAVLRawData10282016.csv</td>\n",
       "      <td>2016-10-28</td>\n",
       "      <td>1.477638e+09</td>\n",
       "      <td>sfmta_2017-02-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ftp_filename  iso_string    time_stamp    gtfs_directory\n",
       "0   sfmtaAVLRawData12052016.csv  2016-12-05  1.480925e+09  sfmta_2017-02-10\n",
       "1   sfmtaAVLRawData12042016.csv  2016-12-04  1.480838e+09  sfmta_2017-02-10\n",
       "2   sfmtaAVLRawData12032016.csv  2016-12-03  1.480752e+09  sfmta_2017-02-10\n",
       "3   sfmtaAVLRawData11232016.csv  2016-11-23  1.479888e+09  sfmta_2017-02-10\n",
       "4   sfmtaAVLRawData11222016.csv  2016-11-22  1.479802e+09  sfmta_2017-02-10\n",
       "5   sfmtaAVLRawData11212016.csv  2016-11-21  1.479715e+09  sfmta_2017-02-10\n",
       "6   sfmtaAVLRawData11202016.csv  2016-11-20  1.479629e+09  sfmta_2017-02-10\n",
       "7   sfmtaAVLRawData11192016.csv  2016-11-19  1.479542e+09  sfmta_2017-02-10\n",
       "8   sfmtaAVLRawData11182016.csv  2016-11-18  1.479456e+09  sfmta_2017-02-10\n",
       "9   sfmtaAVLRawData11172016.csv  2016-11-17  1.479370e+09  sfmta_2017-02-10\n",
       "10  sfmtaAVLRawData11162016.csv  2016-11-16  1.479283e+09  sfmta_2017-02-10\n",
       "11  sfmtaAVLRawData11152016.csv  2016-11-15  1.479197e+09  sfmta_2017-02-10\n",
       "12  sfmtaAVLRawData11142016.csv  2016-11-14  1.479110e+09  sfmta_2017-02-10\n",
       "13  sfmtaAVLRawData11132016.csv  2016-11-13  1.479024e+09  sfmta_2017-02-10\n",
       "14  sfmtaAVLRawData11122016.csv  2016-11-12  1.478938e+09  sfmta_2017-02-10\n",
       "15  sfmtaAVLRawData11112016.csv  2016-11-11  1.478851e+09  sfmta_2017-02-10\n",
       "16  sfmtaAVLRawData11102016.csv  2016-11-10  1.478765e+09  sfmta_2017-02-10\n",
       "17  sfmtaAVLRawData11092016.csv  2016-11-09  1.478678e+09  sfmta_2017-02-10\n",
       "18  sfmtaAVLRawData11082016.csv  2016-11-08  1.478592e+09  sfmta_2017-02-10\n",
       "19  sfmtaAVLRawData11072016.csv  2016-11-07  1.478506e+09  sfmta_2017-02-10\n",
       "20  sfmtaAVLRawData11062016.csv  2016-11-06  1.478416e+09  sfmta_2017-02-10\n",
       "21  sfmtaAVLRawData11052016.csv  2016-11-05  1.478329e+09  sfmta_2017-02-10\n",
       "22  sfmtaAVLRawData11042016.csv  2016-11-04  1.478243e+09  sfmta_2017-02-10\n",
       "23  sfmtaAVLRawData11032016.csv  2016-11-03  1.478156e+09  sfmta_2017-02-10\n",
       "24  sfmtaAVLRawData11022016.csv  2016-11-02  1.478070e+09  sfmta_2017-02-10\n",
       "25  sfmtaAVLRawData11012016.csv  2016-11-01  1.477984e+09  sfmta_2017-02-10\n",
       "26  sfmtaAVLRawData10312016.csv  2016-10-31  1.477897e+09  sfmta_2017-02-10\n",
       "27  sfmtaAVLRawData10302016.csv  2016-10-30  1.477811e+09  sfmta_2017-02-10\n",
       "28  sfmtaAVLRawData10292016.csv  2016-10-29  1.477724e+09  sfmta_2017-02-10\n",
       "29  sfmtaAVLRawData10282016.csv  2016-10-28  1.477638e+09  sfmta_2017-02-10"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the Block and Sign reference dataframes\n",
    "\n",
    "This gives us the appropriate blocks for each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "blockref = pd.read_csv('data/lookUpBlockIDToBlockNumNam.csv')\n",
    "signref = pd.read_csv('data/lookUpSignUpPeriods.csv', parse_dates=[2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to MongoDB, create our database and two tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('localhost', 27017)\n",
    "\n",
    "db = client['avl_pipeline_test']\n",
    "in_collection = db['avl_raw']\n",
    "out_collection = db['labeled_trips']\n",
    "\n",
    "# Optional - Clean the collections\n",
    "in_collection.delete_many({})\n",
    "out_collection.delete_many({});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_collection.delete_many({});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each day, filter and load in the data from the FTP server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data from: 2016-12-05\n",
      "Loading Data from: 2016-12-04\n",
      "Loading Data from: 2016-12-03\n",
      "Loading Data from: 2016-11-23\n",
      "Loading Data from: 2016-11-22\n",
      "Loading Data from: 2016-11-21\n",
      "Loading Data from: 2016-11-20\n",
      "Loading Data from: 2016-11-19\n",
      "Loading Data from: 2016-11-18\n",
      "Loading Data from: 2016-11-17\n",
      "Loading Data from: 2016-11-16\n",
      "Loading Data from: 2016-11-15\n",
      "Loading Data from: 2016-11-14\n",
      "Loading Data from: 2016-11-13\n",
      "Loading Data from: 2016-11-12\n",
      "Loading Data from: 2016-11-11\n",
      "Loading Data from: 2016-11-10\n",
      "Loading Data from: 2016-11-09\n",
      "Loading Data from: 2016-11-08\n",
      "Loading Data from: 2016-11-07\n",
      "Loading Data from: 2016-11-06\n",
      "Loading Data from: 2016-11-05\n",
      "Loading Data from: 2016-11-04\n",
      "Loading Data from: 2016-11-03\n",
      "Loading Data from: 2016-11-02\n",
      "Loading Data from: 2016-11-01\n",
      "Loading Data from: 2016-10-31\n",
      "Loading Data from: 2016-10-30\n",
      "Loading Data from: 2016-10-29\n",
      "Loading Data from: 2016-10-28\n"
     ]
    }
   ],
   "source": [
    "for series in file_df.iterrows():\n",
    "    print (\"Loading Data from: \" + series[1]['iso_string'])\n",
    "    series_transform = series[1].to_frame().T\n",
    "    etl = muni_etl.MuniETL(series_transform, blockref, signref, 'avl_pipeline_test', 'avl_raw')\n",
    "    etl.run_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the amount of data in our collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283822"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_collection.find().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now let's label everything\n",
    "\n",
    "Let's create a class instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeler = lblng.Labeling(in_collection, out_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find all the trip starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Start Intersection Count:  13999\n",
      "\n",
      "\n",
      "Start Count:  1617\n",
      "\n",
      "\n",
      "Duplicate ID Count:  0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labeler.label_single_starts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's use all those starts to label the rest of the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Good Trips:  1474\n",
      "\n",
      "\n",
      "Total Emtpy Trips:  1\n",
      "\n",
      "\n",
      "Total Sparse Trips:  106\n",
      "\n",
      "\n",
      "Total Dense Trips:  22\n",
      "\n",
      "\n",
      "Total 'Endless' Trips:  36\n"
     ]
    }
   ],
   "source": [
    "labeler.label_trips()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweet!! How many documents in our labeled collection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111798"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_collection.find().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('5ae4dcb33ad39e1721401dad'),\n",
       " 'HEADING': '82.0',\n",
       " 'LATITUDE': '37.78693',\n",
       " 'LONGITUDE': '-122.4565',\n",
       " 'PREDICTABLE': '1',\n",
       " 'REPORT_TIME': '10/28/2016 00:27:57',\n",
       " 'REV': '1526',\n",
       " 'SPEED': '0.0',\n",
       " 'TRAIN_ASSIGNMENT': '3305',\n",
       " 'VEHICLE_TAG': '5419',\n",
       " 'sched_time_diff_seconds': 123,\n",
       " 'service_id': 1,\n",
       " 'time_stamp': 1477639677.0,\n",
       " 'trip_id': 7253717,\n",
       " 'trip_id_iso': '7253717_2016-10-28_HKH3O',\n",
       " 'trip_start': 1}"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_collection.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sfmta_2017-02-10'"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeler.gtfs_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6293])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeler.sched_trps[labeler.sched_trps['stop_sequence'] == 1]['stop_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes = pd.read_csv('data/gtfs/sfmta_2017-02-10/routes.txt')\n",
    "trips = pd.read_csv('data/gtfs/sfmta_2017-02-10/trips.txt')\n",
    "sched = pd.read_csv('data/gtfs/sfmta_2017-02-10/stop_times.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>agency_id</th>\n",
       "      <th>route_short_name</th>\n",
       "      <th>route_long_name</th>\n",
       "      <th>route_desc</th>\n",
       "      <th>route_type</th>\n",
       "      <th>route_url</th>\n",
       "      <th>route_color</th>\n",
       "      <th>route_text_color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>11668</td>\n",
       "      <td>SFMTA</td>\n",
       "      <td>33</td>\n",
       "      <td>ASHBURY-18TH ST</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    route_id agency_id route_short_name  route_long_name route_desc  \\\n",
       "39     11668     SFMTA               33  ASHBURY-18TH ST              \n",
       "\n",
       "    route_type route_url route_color route_text_color  \n",
       "39           3                                         "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routes[routes['route_short_name'] == '33']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "east_33 = trips[(trips['route_id'] == 11668) & (trips['direction_id'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_ids = east_33['trip_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6293])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_sched = sched[(sched['trip_id'].isin(trip_ids)) & (sched['stop_sequence'] == 1)]\n",
    "trip_sched['stop_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
